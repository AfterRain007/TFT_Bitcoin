input_chunk_length,output_chunk_length,hidden_size,lstm_layers,num_attention_heads,dropout,hidden_continuous_size,batch_size,full_attention,lr,RMSE,training_time,predicting_time,model,epochs,valEpochs
24,29,10,1,2,0.015414137031707109,8,128,True,0.0006626593159336124,0.5097863674163818,24.71789836883545,0.27916741371154785,TFT,4,2
25,29,31,2,3,0.2568092965505645,8,128,False,3.3100885870819664e-05,0.1535472422838211,35.930556297302246,0.3228795528411865,TFT,4,2
